---
title: Parametric vs Non-Parametric Models
sidebar_position: 6
---

:::tip ğŸŒŸ Day 06 Highlight
**Parametric vs Non-Parametric Models**  
Understand how assumptions about data shape **model flexibility, scalability, and performance**.
:::

## ğŸ“š Table of Contents
- [Overview](#overview)
- [What are Parametric Models?](#what-are-parametric-models)
- [What are Non-Parametric Models?](#what-are-non-parametric-models)
- [Key Differences](#key-differences)
- [Biasâ€“Variance Perspective](#biasvariance-perspective)
- [System Design Considerations](#system-design-considerations)
- [Key Takeaways](#key-takeaways)
- [Quick Summary](#quick-summary)
- [References](#references)

---

## Overview

Another powerful way to categorize Machine Learning models is based on **how many assumptions they make about data**.

- **Parametric Models** â†’ Fixed number of parameters  
- **Non-Parametric Models** â†’ Flexible number of parameters  

This distinction directly impacts **generalization, data requirements, interpretability, and scalability**.

---

## What are Parametric Models?

Parametric models assume a **specific functional form** for the data and summarize learning using a **fixed set of parameters**, regardless of dataset size.

### Key Characteristics
- Fixed number of parameters
- Strong assumptions about data distribution
- Faster training and inference
- Easier to interpret
- Performs well with limited data

### Common Examples
- Linear Regression
- Logistic Regression
- Naive Bayes
- Linear SVM

### Intuition
> â€œI assume the data follows a known pattern â€” I just need to learn the parameters.â€

---

## What are Non-Parametric Models?

Non-parametric models make **fewer assumptions** and allow model complexity to **grow with data**.

### Key Characteristics
- Flexible number of parameters
- Minimal assumptions about data
- Captures complex patterns
- Requires more data
- Higher computational cost

### Common Examples
- k-Nearest Neighbors (k-NN)
- Decision Trees
- Random Forests
- Kernel SVMs

### Intuition
> â€œIâ€™ll adapt my structure based on what the data looks like.â€

---

## Key Differences

| Aspect | Parametric Models | Non-Parametric Models |
|-----|------------------|----------------------|
| Parameters | Fixed | Grows with data |
| Assumptions | Strong | Weak |
| Flexibility | Low | High |
| Data Need | Lowâ€“Medium | High |
| Interpretability | High | Lower |
| Compute Cost | Low | High |

---

## Biasâ€“Variance Perspective

- **Parametric Models**
  - Higher bias
  - Lower variance
  - Risk of underfitting

- **Non-Parametric Models**
  - Lower bias
  - Higher variance
  - Risk of overfitting

This makes the choice **context-dependent**, not â€œone is better than the other.â€

---

## System Design Considerations

Choose **Parametric Models** when:
- Data is limited
- Interpretability is important
- Low-latency inference is required
- Simpler deployment is preferred

Choose **Non-Parametric Models** when:
- Data is abundant
- Relationships are complex
- Accuracy is prioritized over interpretability
- Compute resources are available

---

## Key Takeaways

- Parametric models trade flexibility for simplicity and speed
- Non-parametric models trade efficiency for expressive power
- The decision affects **cost, latency, accuracy, and maintainability**
- Real-world ML systems often start parametric, then evolve

---

## Quick Summary

:::info â±ï¸ 5-Minute Recap
- **What you learned:**  
  How parametric and non-parametric models differ in assumptions and flexibility

- **Why it matters:**  
  This choice impacts biasâ€“variance tradeoff, scalability, and production readiness

- **Whatâ€™s next:**  
  **Biasâ€“Variance Tradeoff** â€” the core principle behind model selection
:::

---

## References

- Stanford CS229 â€” *Model Complexity & Generalization*  
- GÃ©ron, A. â€” *Hands-On Machine Learning*  
- IBM â€” *Parametric vs Non-Parametric Models*
